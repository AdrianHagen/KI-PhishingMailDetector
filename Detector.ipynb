{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras import layers, models, callbacks\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phishing E-Mail Detector\n",
    "Dieses Notebook enthält ein Modell, das vorhersagen kann, ob ein gegebenes Embedding einer E-Mail eine Phishing-Mail ist oder sicher ist. Um dies zu erreichen, lädt es zuvor erstellte Embeddings von E-Mails, die entweder als Phishing oder sicher klassifiziert wurden. Anschließend werden die Daten in Trainings-, Validierungs- und Testdatensätze aufgeteilt, bevor ein Modell mit den Daten definiert und trainiert wird. Schließlich wird die Leistung des Modells bewertet. Die grundlegende Struktur orientiert sich an CRISP-DM.\n",
    "## CRISP-DM Phasen\n",
    "\n",
    "1. Business Understanding\n",
    "2. Data Understanding\n",
    "3. Data Preparation\n",
    "4. Modeling\n",
    "5. Evaluation\n",
    "6. Deployment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kontext\n",
    "### Georgiev International GmbH \n",
    "Kleines Eisenguss Unternehmen, welches sich vor einem Jahr seine IT-Infrastruktur aufgesetzt hat. Leider erhält dieses Unternehmen viele Phishing Mails aus Bulgarien. Daher wurden die Studenten der DHBW beauftragt einen Phishing Filter für deren Gmail Accounts zu entwickeln."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Business Understanding\n",
    "\n",
    "##### Aufgbabe\n",
    "Entwicklung eines Modells, das vorhersagen kann, ob eine Email Phishing ist oder nicht.\n",
    "\n",
    "##### Ziele\n",
    "- Reduzieren der Anzahl an Phishing Mails, die in der Inbox des Nutzers landen.\n",
    "- Minimieren von False Positives um sicherzustellen, dass legitime Emails nicht fälschlicherweise als Phishing gekennzeichnet werden.\n",
    "- Verbessern des allgemeinen Nutzervertrauens\n",
    "\n",
    "##### Erfolgskriterien\n",
    "- Erreichen einer Genauigkeit von über 90%\n",
    "- False Positive Rate unter 5%\n",
    "- False Negative Rate unter 2%\n",
    "\n",
    "##### Stakeholder\n",
    "- Geschäftsführer der Georgiev International GmbH \"Marco\"\n",
    "\n",
    "##### Benötigt werden\n",
    "- Zugang zu historischen Email-Daten mit gelabelten Beispielen von Phishing und Non-Phishing Emails.\n",
    "- Infrastruktur zum Entwickeln, Testen und Produktiv Setzen des Modells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 2. Data Understanding\n",
    "Die Daten kommen aus folendem Datensatz: https://www.kaggle.com/datasets/subhajournal/phishingemails/data. \n",
    "\n",
    "- 18.600 E-Mails im Datensatz\n",
    "- 61% sicher, 39% Phishing\n",
    "- Moderates Ungleichgewicht\n",
    "- Gefahr von Modell-Bias zugunsten sicherer E-Mails\n",
    "- 3% leere E-Mails\n",
    "\n",
    "Der Datensatz enthält drei Spalten:\n",
    "    \n",
    "1. Die Anzahl an Einträgen\n",
    "2. Den Email Text\n",
    "3. Das Email Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/Phishing_Email.csv\", skiprows=0)\n",
    "\n",
    "print(f\"The amount of data entries is: {len(data)}\\n\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entfernen von leeren Datensätzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing text\n",
    "data = data.dropna(subset=[\"Email Text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lösen des Data Imbalance Problems durch Löschen überschüssiger Safe Emails\n",
    "Wie bereits im Data Understanding beschrieben liegt nur ein moderates Ungleichgewicht vor, ein Lösen des Data Imbalance Problems durch das Löschen überschüssiger Safe Emails macht also ggf. keinen signifikanten Unterschied. \n",
    "\n",
    "Zum Vergleich: \n",
    "\n",
    "F-Wert ohne Löschen = 0.9167\n",
    "\n",
    "F-Wert mit Löschen = 0.9465\n",
    "\n",
    "Ein Löschen der überschüssigen Daten zeigt also Vorteile, weswegen es hier gemacht wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excess_safe_mails = data[data['Email Type'] == 'Safe Email'].shape[0] - data[data['Email Type'] == 'Phishing Email'].shape[0]\n",
    "print(f\"Excess Safe Mails before resolving data imbalance: {excess_safe_mails}\")\n",
    "\n",
    "# Filter the DataFrame to get rows with the specified value\n",
    "filtered_df = data[data['Email Type'] == 'Safe Email']\n",
    "\n",
    "# Randomly select entries to remove\n",
    "rows_to_remove = filtered_df.sample(n=excess_safe_mails, random_state=1).index\n",
    "\n",
    "# Drop the selected entries from the original DataFrame\n",
    "data = data.drop(rows_to_remove)\n",
    "\n",
    "excess_safe_mails = data[data['Email Type'] == 'Safe Email'].shape[0] - data[data['Email Type'] == 'Phishing Email'].shape[0]\n",
    "print(f\"Excess Safe Mails after resolving data imbalance: {excess_safe_mails}\")\n",
    "n_safe_mails = data[data['Email Type'] == 'Safe Email'].shape[0]\n",
    "n_phishing_mail = data[data['Email Type'] == 'Phishing Email'].shape[0]\n",
    "print(f\"Number of Safe Mails: {n_safe_mails}, Number of Phishing Mails: {n_phishing_mail}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datenaufbereitung\n",
    "Hier werden folgende Datenaufbereitungsschritte unternommen\n",
    "- Alle Buchstaben zu Kleinbuchstaben machen\n",
    "- Entfernen von Punktzeichen \n",
    "- Entfernen von Stopwords\n",
    "- Tokenization\n",
    "- Stemming\n",
    "- Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_texts(texts):\n",
    "    # Convert to lowercase\n",
    "    texts = [text.lower() for text in texts]\n",
    "\n",
    "    # Remove punctuation\n",
    "    texts = [text.translate(str.maketrans(\"\", \"\", string.punctuation)) for text in texts]\n",
    "\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    texts = [' '.join(word for word in text.split() if word not in stop_words) for text in texts]\n",
    "\n",
    "    # Tokenize\n",
    "    texts = [word_tokenize(text) for text in texts]\n",
    "\n",
    "    # Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    texts = [[stemmer.stem(word) for word in text] for text in texts]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    texts = [[lemmatizer.lemmatize(word) for word in text] for text in texts]\n",
    "\n",
    "    # Join tokens back into strings\n",
    "    texts = [' '.join(text) for text in texts]\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erstellen der Embeddings\n",
    "- Nutzen des Sentence Transformer Modells allMiniLM (https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)\n",
    "- Beim Ersten Durchlaufen des Notebooks werden diese in einer Datei gespeichert, die dann in weiteren Durchläufen ausgelesen wird um die Performance zu verbessern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(texts):\n",
    "    # Load the sentence transformer model\n",
    "    sentence_transformer_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    \n",
    "    # Preprocess the data\n",
    "    cleaned_texts = clean_texts(texts)\n",
    "\n",
    "    # Encode the text data to get embeddings\n",
    "    embeddings = sentence_transformer_model.encode(cleaned_texts, show_progress_bar=True)\n",
    "\n",
    "    # Convert embeddings to a list of lists with Python floats\n",
    "    embeddings_list = [list(map(float, embedding)) for embedding in embeddings]\n",
    "\n",
    "    # Convert embeddings to a single string representation\n",
    "    embeddings_str_list = [str(embedding) for embedding in embeddings_list]\n",
    "    \n",
    "    return embeddings_str_list\n",
    "\n",
    "# Check if the embeddings exist and if not, create them\n",
    "if not os.path.exists(\"data/embeddings.csv\"):\n",
    "    # Create a new DataFrame with a single column for embeddings\n",
    "    embeddings_df = pd.DataFrame({\"embedding\": get_embeddings(data[\"Email Text\"].tolist())})\n",
    "\n",
    "    # Concatenate the label column with the embeddings\n",
    "    final_df = pd.concat([data[\"Email Type\"].reset_index(drop=True), embeddings_df], axis=1)\n",
    "    \n",
    "    # Save the final DataFrame to a CSV file\n",
    "    final_df.to_csv(\"data/embeddings.csv\", index=False, sep=\";\")\n",
    "\n",
    "# Load the embeddings and skip the header\n",
    "data_embeddings = pd.read_csv('data/embeddings.csv', sep=';', skiprows=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erstellen eines Trainings, Validations und Testdatensatzes\n",
    "Dazu wird die Aufteilung 60% Trainingsdate, 20% Validationsdaten und 20% Testdaten genutzt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying the test split is not necessary for the code, but is done anyway for clarity\n",
    "def format_and_load_data(train_split=0.6, validate_split=0.2, test_split=0.2):\n",
    "    # Calculate the number of samples for each dataset split\n",
    "    train_amount = int(len(data) * train_split)\n",
    "    validate_amount = int(len(data) * validate_split)\n",
    "    \n",
    "    examples = []\n",
    "\n",
    "    # Process each embedding\n",
    "    for _, embedding in data_embeddings.iterrows():\n",
    "        label = 1 if embedding.iloc[0] == 'Phishing Email' else 0\n",
    "        embedding_list = [float(i) for i in embedding.iloc[1].strip('[]').split(', ')]\n",
    "        examples.append((embedding_list, label))\n",
    "\n",
    "    # Shuffle the examples\n",
    "    np.random.shuffle(examples)\n",
    "\n",
    "    # Split data into features and labels\n",
    "    X, y = zip(*examples)\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Split data into training, validation and testing sets\n",
    "    X_train = X[:train_amount]\n",
    "    X_val = X[train_amount:train_amount + validate_amount]\n",
    "    X_test = X[train_amount + validate_amount:]\n",
    "    y_train = y[:train_amount]\n",
    "    y_val = y[train_amount:train_amount + validate_amount]\n",
    "    y_test = y[train_amount + validate_amount:]\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erstellen eines binären Klassifizierungsmodells, um vorherzusagen, ob eine E-Mail Phishing ist.\n",
    "\n",
    "Das Modell besteht aus drei Schichten:\n",
    "- Die erste Schicht akzeptiert Eingaben mit der Länge der erstellten Einbettungen (hier 384).\n",
    "- Die zweite Schicht akzeptiert Eingaben mit der Länge 128.\n",
    "- Die dritte Schicht akzeptiert Eingaben mit der Länge 1.\n",
    "\n",
    "- Ersten beiden Schichten verwenden die ReLU-Aktivierungsfunktion\n",
    "- Letzte Schicht verwendet Sigmoid.\n",
    "    - Sigmoid wurde gewählt, weil es Werte zwischen 0 und 1 ausgibt, was es für binäre Klassifizierungsaufgaben geeignet macht. (Es wird auch sehr häufig für diese Art von Aufgaben verwendet.)\n",
    "\n",
    "Während des Trainings werden die Validierungsdaten und der Validierungsverlust verwendet, um das Modell nach jeder Epoche zu bewerten. Die Validierungsgenauigkeit wurde ebenfalls berücksichtigt, zeigte jedoch schwächere Ergebnisse als die Verlustmetrik.\n",
    "\n",
    "Um den Trainingsprozess effektiv zu verwalten, werden zwei Callback-Funktionen verwendet:\n",
    "- **Early Stopping**: Stoppt das Training, wenn die Leistung des Modells, gemessen am Validierungsdatensatz, zu verschlechtern beginnt, um Überanpassung zu verhindern.\n",
    "- **Reduce Learning Rate on Plateau**: Passt die Lernrate an (in diesem Fall, indem sie halbiert wird), wenn die Leistung des Modells zu sinken beginnt, um zu verhindern, dass es in lokalen Minima stecken bleibt. \n",
    "\n",
    "    Der Patience-Parameter für beide Callbacks definiert die Anzahl der Epochen, die sie abwarten, bevor sie Maßnahmen ergreifen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data splits\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = format_and_load_data()\n",
    "\n",
    "# Reshape data to make it acceptable for the model\n",
    "y_train = np.array(y_train, dtype=np.int32)\n",
    "y_val = np.array(y_val, dtype=np.int32)\n",
    "y_test = np.array(y_test, dtype=np.int32)\n",
    "\n",
    "print(X_train.shape, X_train[0].shape)\n",
    "\n",
    "# Define model architecture\n",
    "no_embedding_dim = len(X_train[0])\n",
    "model = models.Sequential([\n",
    "    layers.Dense(no_embedding_dim, activation='relu', input_shape=(no_embedding_dim,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = callbacks.EarlyStopping(patience=5, monitor='val_loss', restore_best_weights=True)\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(factor=0.5, patience=2, monitor='val_loss', verbose=1)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# Save the model for later use\n",
    "model.save(\"models/phishing_email_classifier.h5\")\n",
    "\n",
    "model_summary = model.summary()\n",
    "model_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss and accuracy\n",
    "- **Verlust (Loss)**: Misst die Differenz zwischen vorhergesagten und tatsächlichen Werten.\n",
    "\n",
    "- **Genauigkeit (Accuracy)**: Gibt an, wie oft das Modell korrekte Vorhersagen trifft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1-Score\n",
    "Der F1-Wert berechnet sich als harmonisches Mittel zwischen Precision und Recall, die jeweils wie folgt berechnet werden:\n",
    "\n",
    "- **Precision**: Die Precision misst das Verhältnis der korrekt als positiv vorhergesagten Instanzen zur Gesamtanzahl der positiv vorhergesagten Instanzen. Sie wird berechnet als:\n",
    "  $$\n",
    "  \\text{Precision} = \\frac{TP}{TP + FP}\n",
    "  $$\n",
    "  Dabei sind \\(TP\\) die richtig positiven Vorhersagen (true positives) und \\(FP\\) die falsch positiven Vorhersagen (false positives).\n",
    "\n",
    "- **Recall**: Der Recall (auch Sensitivität genannt) misst das Verhältnis der korrekt als positiv vorhergesagten Instanzen zur Gesamtanzahl der tatsächlich positiven Instanzen. Er wird berechnet als:\n",
    "  $$\n",
    "  \\text{Recall} = \\frac{TP}{TP + FN}\n",
    "  $$\n",
    "\n",
    "  Hierbei sind \\(TP\\) die richtig positiven Vorhersagen und \\(FN\\) die falsch negativen Vorhersagen (false negatives).\n",
    "\n",
    "- **F1-Score**:\n",
    "  $$\n",
    "  \\text{F1-Score} = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = model.predict(X_test).flatten()\n",
    "y_pred = (y_pred_prob > 0.5).astype(np.int32)\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f'Precision: {precision:.4f}')\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f'Recall: {recall:.4f}')\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'F1 Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC AUC Score\n",
    "\n",
    "- **ROC-AUC (Receiver Operating Characteristic - Area Under the Curve)**: Der ROC-AUC-Wert misst die Fähigkeit eines binären Klassifikators, zwischen positiven und negativen Klassen zu unterscheiden, unabhängig von der gewählten Klassifikationsschwelle.\n",
    "\n",
    "  Der ROC-AUC-Wert wird berechnet, indem die Fläche unter der ROC-Kurve betrachtet wird. Die ROC-Kurve zeigt das Verhältnis von True Positive Rate (TPR) zu False Positive Rate (FPR) für verschiedene Klassifikationsschwellen. Ein höherer ROC-AUC-Wert (normalerweise im Bereich von 0 bis 1) deutet auf ein besseres Modell hin, das besser zwischen den Klassen unterscheiden kann.\n",
    "\n",
    "  Eine ROC-AUC von 0,5 bedeutet, dass das Modell nicht besser als zufällige Vorhersagen ist, während ein Wert nahe 1 zeigt, dass das Modell eine sehr gute Trennung zwischen den Klassen erreicht hat.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "print(f'ROC AUC Score: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix\n",
    "\n",
    "- **True Positives (TP)**: Korrekt als positiv vorhergesagte Instanzen.\n",
    "- **False Positives (FP)**: Fälschlicherweise als positiv vorhergesagte Instanzen.\n",
    "- **True Negatives (TN)**: Korrekt als negativ vorhergesagte Instanzen.\n",
    "- **False Negatives (FN)**: Fälschlicherweise als negativ vorhergesagte Instanzen.\n",
    "\n",
    "\n",
    "Ein Beispiel für die Darstellung einer Confusion Matrix:\n",
    "\n",
    "|                 | Predicted Negative | Predicted Positive |\n",
    "|-----------------|--------------------|--------------------|\n",
    "| **Actual Negative** | TN                 | FP                 |\n",
    "| **Actual Positive** | FN                 | TP                 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Extracting elements from the confusion matrix\n",
    "TN, FP, FN, TP = conf_mat.ravel()\n",
    "\n",
    "# Calculating false positive rate and false negative rate\n",
    "Total_Predictions = FP + FN + TP + TN\n",
    "False_Positive_Rate = FP / Total_Predictions\n",
    "False_Negative_Rate = FN / Total_Predictions\n",
    "\n",
    "print(f\"False Positive Rate: {False_Positive_Rate}\")\n",
    "print(f\"False Negative Rate: {False_Negative_Rate}\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            annot_kws={'fontsize': 14, 'fontweight': 'bold'})\n",
    "plt.xlabel('Predicted Labels', fontsize=14)\n",
    "plt.ylabel('True Labels', fontsize=14)\n",
    "plt.title('Confusion Matrix', fontsize=16)\n",
    "plt.xticks(ticks=[0.5, 1.5], labels=['Not Phishing', 'Phishing'])\n",
    "plt.yticks(ticks=[0.5, 1.5], labels=['Not Phishing', 'Phishing'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Deployment\n",
    "Das Modell kann zur Nutzung aus dem models Ordner geladen und dann genutzt werden. Nachfolgend ist beispielhaft die Nutzung des Modells gezeigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model for phishing email classification\n",
    "model = keras.models.load_model(\"models/phishing_email_classifier.h5\")\n",
    "\n",
    "# Creating sample mails on my own to test and demonstrate the model\n",
    "mails = [\"You won the lottery! Please send us your bank account details to claim your prize.\",\n",
    "         \"Hello I am a Nigerian prince and I want to share my fortune with you. Please send me your bank account details so I can transfer the money to you.\",\n",
    "         \"Hello I am just confirming that I got your previous email and I will get back to you soon. Thanks\"]\n",
    "\n",
    "# Encode the preprocessed email text to get its embedding\n",
    "email_embeddings = get_embeddings(mails)\n",
    "\n",
    "email_embeddings_formatted = []\n",
    "# Process each embedding\n",
    "for ee in email_embeddings:\n",
    "    embedding_list = [float(i) for i in ee.strip('[]').split(', ')]\n",
    "    email_embeddings_formatted.append(embedding_list)\n",
    "    \n",
    "email_embeddings_formatted = np.array(email_embeddings_formatted)\n",
    "\n",
    "# Make predictions for each embedding\n",
    "predictions = model.predict(email_embeddings_formatted)\n",
    "\n",
    "# Thresholding the predictions\n",
    "threshold = 0.5\n",
    "predicted_labels = [\"Phishing\" if prediction[0] >= threshold else \"Safe\" for prediction in predictions]\n",
    "\n",
    "# Print predictions for each mail\n",
    "for mail, prediction in zip(mails, predicted_labels):\n",
    "    print(f\"Mail: {mail}\\nPrediction: {prediction}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
